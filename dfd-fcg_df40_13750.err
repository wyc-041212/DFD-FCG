[rank: 0] Seed set to 1019
Using 16bit Automatic Mixed Precision (AMP)
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
`Trainer(val_check_interval=1.0)` was configured so validation will run at the end of the training epoch..
wandb: Currently logged in as: 1160885822 (1160885822-hong-kong-baptist-university). Use `wandb login --relogin` to force relogin
wandb: wandb version 0.24.1 is available!  To upgrade, please run:
wandb:  $ pip install wandb --upgrade
wandb: Tracking run with wandb version 0.16.3
wandb: Run data is saved locally in ./logs/wandb/run-20260130_151544-6513d8zl
wandb: Run `wandb offline` to turn off syncing.
wandb: Syncing run fast-lion-8
wandb: â­ï¸ View project at https://wandb.ai/1160885822-hong-kong-baptist-university/DFD-FCG
wandb: ğŸš€ View run at https://wandb.ai/1160885822-hong-kong-baptist-university/DFD-FCG/runs/6513d8zl
wandb: WARNING Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
Restoring states from the checkpoint path at /home/comp/f2256768/DFD-FCG/logs/DFD-FCG/yv0e82m8/checkpoints/last.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
Restored all states from the checkpoint at /home/comp/f2256768/DFD-FCG/logs/DFD-FCG/yv0e82m8/checkpoints/last.ckpt
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]
wandb: WARNING No program path found, not creating job artifact. See https://docs.wandb.ai/guides/launch/create-job
wandb: - 0.013 MB of 0.013 MB uploadedwandb: \ 0.013 MB of 0.024 MB uploadedwandb: | 0.020 MB of 0.024 MB uploadedwandb: / 0.024 MB of 0.024 MB uploadedwandb: 
wandb: Run history:
wandb:                  epoch â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–â–
wandb:               lr-AdamW â–
wandb:     train/ImageDF/loss â–…â–‡â–‡â–‡â–†â–†â–†â–…â–†â–…â–†â–‡â–†â–…â–…â–†â–…â–†â–„â–†â–ˆâ–†â–ƒâ–ˆâ–†â–†â–†â–†â–‡â–†â–…â–‡â–„â–„â–…â–†â–†â–„â–â–†
wandb: train/ImageDF/syno_sim â–„â–„â–„â–„â–„â–„â–†â–†â–„â–ƒâ–„â–†â–„â–ˆâ–â–„â–„â–ƒâ–†â–â–†â–ƒâ–ƒâ–„â–†â–ƒâ–…â–†â–â–ƒâ–†â–†â–†â–‚â–„â–†â–ƒâ–„â–ƒâ–ƒ
wandb:    trainer/global_step â–â–â–â–â–‚â–‚â–‚â–‚â–‚â–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–ƒâ–„â–„â–„â–„â–„â–…â–…â–…â–…â–…â–…â–†â–†â–†â–†â–†â–‡â–‡â–‡â–‡â–‡â–‡â–ˆâ–ˆâ–ˆ
wandb:      valid/ImageDF/acc â–
wandb:      valid/ImageDF/auc â–
wandb:    valid/ImageDF/cm/#0 â–
wandb:    valid/ImageDF/cm/#1 â–
wandb:    valid/ImageDF/cm/#2 â–
wandb:    valid/ImageDF/cm/#3 â–
wandb:     valid/ImageDF/loss â–
wandb: 
wandb: Run summary:
wandb:                  epoch 12
wandb:               lr-AdamW 0.0001
wandb:     train/ImageDF/loss 0.01475
wandb: train/ImageDF/syno_sim 0.02602
wandb:    trainer/global_step 179217
wandb:      valid/ImageDF/acc 0.97
wandb:       valid/ImageDF/ap nan
wandb:      valid/ImageDF/auc 0.0
wandb:    valid/ImageDF/cm/#0 0.97
wandb:    valid/ImageDF/cm/#1 0.03
wandb:    valid/ImageDF/cm/#2 0.0
wandb:    valid/ImageDF/cm/#3 0.0
wandb:     valid/ImageDF/loss 0.26547
wandb: 
wandb: ğŸš€ View run fast-lion-8 at: https://wandb.ai/1160885822-hong-kong-baptist-university/DFD-FCG/runs/6513d8zl
wandb: Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)
wandb: Find logs at: ./logs/wandb/run-20260130_151544-6513d8zl/logs
Traceback (most recent call last):
  File "/home/comp/f2256768/.conda/envs/dfd-fcg/lib/python3.8/runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "/home/comp/f2256768/.conda/envs/dfd-fcg/lib/python3.8/runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "/home/comp/f2256768/DFD-FCG/main.py", line 123, in <module>
    cli_main()
  File "/home/comp/f2256768/DFD-FCG/main.py", line 116, in cli_main
    scores = inference(cli=cli)
  File "/home/comp/f2256768/DFD-FCG/main.py", line 47, in inference
    results = inference_driver(
  File "/home/comp/f2256768/.conda/envs/dfd-fcg/lib/python3.8/site-packages/torch/utils/_contextlib.py", line 115, in decorate_context
    return func(*args, **kwargs)
  File "/home/comp/f2256768/DFD-FCG/inference.py", line 97, in inference_driver
    gathered_results = [None] * torch.distributed.get_world_size()
  File "/home/comp/f2256768/.conda/envs/dfd-fcg/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 1555, in get_world_size
    return _get_group_size(group)
  File "/home/comp/f2256768/.conda/envs/dfd-fcg/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 836, in _get_group_size
    default_pg = _get_default_group()
  File "/home/comp/f2256768/.conda/envs/dfd-fcg/lib/python3.8/site-packages/torch/distributed/distributed_c10d.py", line 977, in _get_default_group
    raise ValueError(
ValueError: Default process group has not been initialized, please make sure to call init_process_group.
